{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we do in this TP?\n",
    "\n",
    "In this TP, we will delve into the process of fine-tuning a pre-trained model for a specific task. Fine-tuning is a transfer learning method where the weights of an existing pre-trained model serve as the foundation for a new model. This approach is especially beneficial when the new task shares similarities with the original task for which the model was trained. By doing so, we can utilize the learned features of the pre-trained model, thereby reducing the need for extensive data and computational resources. \n",
    "\n",
    "We will tackle an object detection problem using the VOC dataset, which consists of approximately 5000 images for both training and validation. The images have been preprocessed to have (224x224) and contain only one bounding box around the object of interest. We will employ a Resnet18 model pre-trained on the ImageNet dataset as a feature extractor, and develop a model to detect the label and location of the object within the image. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = torch.load('./data/train_data.pt')\n",
    "validation = torch.load('./data/validation_data.pt')\n",
    "test = torch.load('./data/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (utils.py, line 74)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3508\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\n\u001b[1;33m    from utils import visualize_image\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\GitHub\\MOSIG\\intelligent-systems\\TP6-ObjectRecognition\\utils.py:74\u001b[1;36m\u001b[0m\n\u001b[1;33m    inputs, bboxes, labels = #TODO # Get the inputs, bounding boxes and labels\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from utils import visualize_image\n",
    "\n",
    "# Visualize a sample image\n",
    "idx = 4055 # change this to visualize a different image\n",
    "image, bbox, label = train[idx]\n",
    "visualize_image(image, bbox, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: How is the data structured? What do the labels represent? What dimensions does an image have in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 4\n",
      "3 8\n",
      "4 16\n",
      "5 3\n",
      "6 6\n",
      "7 12\n",
      "8 24\n",
      "9 19\n",
      "10 9\n",
      "11 18\n",
      "12 7\n",
      "13 14\n",
      "14 28\n",
      "15 27\n",
      "16 25\n",
      "17 21\n",
      "18 13\n",
      "19 26\n",
      "20 23\n",
      "21 17\n",
      "22 5\n",
      "23 10\n",
      "24 20\n",
      "25 11\n",
      "26 22\n",
      "27 15\n",
      "28 1\n"
     ]
    }
   ],
   "source": [
    "mod = 29\n",
    "n = 1\n",
    "for i in range (29):\n",
    "    print(i, n)\n",
    "    n = (n * 2) % 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(17 * 3 * 3) % 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "from utils import normalize_data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = normalize_data(train)\n",
    "validation_dataset = normalize_data(validation)\n",
    "\n",
    "trainloader = #TODO\n",
    "validationloader = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In object detection tasks, we need to develop both a classifier and a regressor. The classifier's role is to identify the object's label, while the regressor's role is to estimate the object's coordinates.\n",
    "\n",
    "Our classifier and regressor are built as follows:\n",
    "\n",
    "`Classifier`: It consists of two blocks, each containing a sequence of a Linear layer, a ReLU activation function, and a Dropout layer. This is followed by a final fully connected layer.\n",
    "\n",
    "`Regressor`: It consists of two blocks of Linear layer and ReLU activation function, with the final block being a Linear layer and Sigmoid Activation function.\n",
    "\n",
    "\n",
    "You are tasked to complete the model construction `ResNetObjectDetector` in the `model.py` file. Please note that the output from `self.features` has a shape of `(batch_size, 512)` and the number of classes is `20`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ResnetObjectDetector\n",
    "model = ResnetObjectDetector(nb_classes=20)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Print model summary\n",
    "summary(model, input_size=(32, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the model definition, you can now write a train_loop and validation loop to train the model. Complete the function `train_loop` and `validation_loop` in `utils.py`.\n",
    "\n",
    "[OPTIONAL] We will see how to use TensorBoard for monitoring the training process. If you are using VSCode, click on Launch TensorBoard Session, it will then install a tensorboard extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_loop\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "# Train the model\n",
    "now = datetime.now()\n",
    "optimizer = #TODO Define optimizer\n",
    "epoch = #TODO Define number of epochs\n",
    "writer =  SummaryWriter(f'runs/tp6-object-recognition/{now.strftime(\"%Y-%m-%d_%H-%M-%S\")}/')\n",
    "losses, val_losses, acc, val_acc = #TODO\n",
    "\n",
    "writer.flush() # Write to disk\n",
    "writer.close() # Close the writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training process, you can generate plots for both the loss and accuracy curves (assuming you're not using TensorBoard). What conclusions can you draw from these visualizations?\n",
    "\n",
    "By executing the cell below, you can examine the predictions made by the model. Do you see any potential for improving the model, and if so, how would you go about it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import predict\n",
    "\n",
    "# Normalize the test data\n",
    "test_dataset = normalize_data(test)\n",
    "# Predict on test data\n",
    "for i in range(10,20):\n",
    "    img = test_dataset[i][0]\n",
    "    model.to('cpu')\n",
    "    predict(model,image, show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
