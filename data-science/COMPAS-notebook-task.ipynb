{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first analysis of the COMPAS dataset\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "We will examine the ProPublica COMPAS dataset, which contains the records of all criminal defendants who were subject to COMPAS screening in Broward County, Florida, during 2013 and 2014. For each defendant, various information fields (‘features’) were gathered by ProPublica. Broadly, these fields are related to the defendant’s demographic information (e.g., gender and race), criminal history (e.g., the number of prior offenses) and administrative information about the case (e.g., the case number, arrest date). Finally, the dataset contains the risk of recidivism predicted by the COMPAS tool, and also information about whether the defendant did actually recidivate or not (ground truth label for us).\n",
    "\n",
    "The COMPAS score uses answers to 137 questions to assign a risk score to defendants -- essentially an estimate of the likelihood of re-arrest. The actual output is two-fold: a risk rating of 1-10 and a \"low\", \"medium\", or \"high\" risk label.\n",
    "\n",
    "Link to dataset: https://github.com/propublica/compas-analysis\n",
    "\n",
    "The file we will analyze is: compas-scores-two-years.csv\n",
    "\n",
    "Link to the ProPublica article:\n",
    "\n",
    "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "\n",
    "Some of the code below is adapted from the Propublica github repository above, and from\n",
    "\n",
    "https://investigate.ai/propublica-criminal-sentencing/week-5-1-machine-bias-class/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "We first need to load the data from the ProPublica repo:\n",
    "https://github.com/propublica/compas-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file '%s' in the current directory... compas-scores-two-years.csv\n",
      "File found in current directory..\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import urllib.request\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import preprocessing\n",
    "from random import seed, shuffle\n",
    "\n",
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def check_data_file(fname):\n",
    "    files = os.listdir(\".\") # get the current directory listing\n",
    "    print(\"Looking for file '%s' in the current directory...\",fname)\n",
    "\n",
    "    if fname not in files:\n",
    "        print(\"'%s' not found! Downloading from GitHub...\",fname)\n",
    "        addr = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        response = urllib.request.urlopen(addr)\n",
    "        data = response.read()\n",
    "        fileOut = open(fname, \"wb\")\n",
    "        fileOut.write(data)\n",
    "        fileOut.close()\n",
    "        print(\"'%s' download and saved locally..\",fname)\n",
    "    else:\n",
    "        print(\"File found in current directory..\")\n",
    "    \n",
    "COMPAS_INPUT_FILE = \"compas-scores-two-years.csv\"\n",
    "check_data_file(COMPAS_INPUT_FILE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning data\n",
    "\n",
    "The following code load the data using pandas and cleans it according to ProPublica's cleaning: \n",
    "\n",
    "\"\n",
    "If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "\n",
    "We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "\n",
    "In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed\n",
    "\n",
    "We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\" \n",
    "\"\n",
    "\n",
    "Finally, it converts the data to a dictionary with np arrays, which will be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file\n",
    "df = pd.read_csv(COMPAS_INPUT_FILE)\n",
    "# print(df.shape)\n",
    "\n",
    "df = df.dropna(subset=[\"days_b_screening_arrest\"]) # dropping missing vals\n",
    "\n",
    "df = df[\n",
    "    (df.days_b_screening_arrest <= 30) &  \n",
    "    (df.days_b_screening_arrest >= -30) &  \n",
    "    (df.is_recid != -1) &\n",
    "    (df.c_charge_degree != 'O') &\n",
    "    (df.score_text != 'N/A')\n",
    "]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True) # renumber the rows from 0 again\n",
    "# df.shape\n",
    "\n",
    "# Conversion to dictionary with np arrays\n",
    "data = df.to_dict('list')\n",
    "for k in data.keys():\n",
    "    data[k] = np.array(data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>r_days_from_arrest</th>\n",
       "      <th>violent_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5509.259883</td>\n",
       "      <td>34.534511</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>4.418503</td>\n",
       "      <td>0.091218</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>-1.740279</td>\n",
       "      <td>24.903273</td>\n",
       "      <td>0.484446</td>\n",
       "      <td>20.100651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>4.418503</td>\n",
       "      <td>3.641769</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>13.316753</td>\n",
       "      <td>555.049417</td>\n",
       "      <td>0.389825</td>\n",
       "      <td>0.455120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3171.878516</td>\n",
       "      <td>11.730938</td>\n",
       "      <td>0.463599</td>\n",
       "      <td>2.839463</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.470731</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>5.084709</td>\n",
       "      <td>276.812982</td>\n",
       "      <td>0.499799</td>\n",
       "      <td>76.543499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315539</td>\n",
       "      <td>2.839463</td>\n",
       "      <td>2.488768</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>50.138185</td>\n",
       "      <td>400.258400</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.498022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2753.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5521.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>539.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8225.250000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11001.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9485.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>1186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          age  juv_fel_count  decile_score  juv_misd_count  \\\n",
       "count   6172.000000  6172.000000    6172.000000   6172.000000     6172.000000   \n",
       "mean    5509.259883    34.534511       0.059300      4.418503        0.091218   \n",
       "std     3171.878516    11.730938       0.463599      2.839463        0.497872   \n",
       "min        1.000000    18.000000       0.000000      1.000000        0.000000   \n",
       "25%     2753.750000    25.000000       0.000000      2.000000        0.000000   \n",
       "50%     5521.000000    31.000000       0.000000      4.000000        0.000000   \n",
       "75%     8225.250000    42.000000       0.000000      7.000000        0.000000   \n",
       "max    11001.000000    96.000000      20.000000     10.000000       13.000000   \n",
       "\n",
       "       juv_other_count  priors_count  days_b_screening_arrest  \\\n",
       "count      6172.000000   6172.000000              6172.000000   \n",
       "mean          0.110661      3.246436                -1.740279   \n",
       "std           0.470731      4.743770                 5.084709   \n",
       "min           0.000000      0.000000               -30.000000   \n",
       "25%           0.000000      0.000000                -1.000000   \n",
       "50%           0.000000      1.000000                -1.000000   \n",
       "75%           0.000000      4.000000                -1.000000   \n",
       "max           9.000000     38.000000                30.000000   \n",
       "\n",
       "       c_days_from_compas     is_recid  r_days_from_arrest  violent_recid  \\\n",
       "count         6172.000000  6172.000000         1997.000000            0.0   \n",
       "mean            24.903273     0.484446           20.100651            NaN   \n",
       "std            276.812982     0.499799           76.543499            NaN   \n",
       "min              0.000000     0.000000           -1.000000            NaN   \n",
       "25%              1.000000     0.000000            0.000000            NaN   \n",
       "50%              1.000000     0.000000            0.000000            NaN   \n",
       "75%              1.000000     1.000000            1.000000            NaN   \n",
       "max           9485.000000     1.000000          993.000000            NaN   \n",
       "\n",
       "       is_violent_recid  decile_score.1  v_decile_score  priors_count.1  \\\n",
       "count       6172.000000     6172.000000     6172.000000     6172.000000   \n",
       "mean           0.112119        4.418503        3.641769        3.246436   \n",
       "std            0.315539        2.839463        2.488768        4.743770   \n",
       "min            0.000000        1.000000        1.000000        0.000000   \n",
       "25%            0.000000        2.000000        1.000000        0.000000   \n",
       "50%            0.000000        4.000000        3.000000        1.000000   \n",
       "75%            0.000000        7.000000        5.000000        4.000000   \n",
       "max            1.000000       10.000000       10.000000       38.000000   \n",
       "\n",
       "             start          end        event  two_year_recid  \n",
       "count  6172.000000  6172.000000  6172.000000     6172.000000  \n",
       "mean     13.316753   555.049417     0.389825        0.455120  \n",
       "std      50.138185   400.258400     0.487750        0.498022  \n",
       "min       0.000000     0.000000     0.000000        0.000000  \n",
       "25%       0.000000   148.000000     0.000000        0.000000  \n",
       "50%       0.000000   539.500000     0.000000        0.000000  \n",
       "75%       3.000000   914.000000     1.000000        1.000000  \n",
       "max     937.000000  1186.000000     1.000000        1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # check some examples of data\n",
    "df.columns # prints the features\n",
    "df.isnull().sum() #check for missing values\n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset\n",
    "\n",
    "The following pandas commands are very convenient to explore the data. Uncomment them to explore the data. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Add a command to print the number of defendents per race. \n",
    "\n",
    "In the following, we will look mostly at African-Americans and Caucasians(termed blacks and whites for short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "African-American    3175\n",
       "Caucasian           2103\n",
       "Hispanic             509\n",
       "Other                343\n",
       "Asian                 31\n",
       "Native American       11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # check some examples of data\n",
    "df.columns # prints the features\n",
    "df.isnull().sum() #check for missing values\n",
    "df.describe() # generates descriptive statistics (e.g., to check for outliers)\n",
    "df.race.unique() # different races we have in the dataset\n",
    "df.age_cat.value_counts() #number of people by age category\n",
    "df.score_text.value_counts() #number of people by COMPAS risk category\n",
    "\n",
    "# TODO: Insert your code below this\n",
    "df.race.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis of the bias in COMPAS scores\n",
    "\n",
    "We now look at the COMPAS scores (deciles first, then text scores) as a function of the sensitive attribute (race or gender) to observe potential differences. \n",
    "\n",
    "We start by observing the scores for different groupes. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Plot the histograms of decile scores for Black and White defendant and observe the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of decile scores for Blacks (blue) and Whites (orange)\n",
    "# TODO: Insert your code below this\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#bins = numpy.linspace(0, 10, 200)\n",
    "# df[df.race == 'Caucasian']['decile_score'].plot(kind='hist', title='Blue Defendant\\'s Decile Scores ')\n",
    "# df[df.race == 'African-American']['decile_score'].plot(kind='hist', title='Orange Defendant\\'s Decile Scores ')\n",
    "\n",
    "bins = np.linspace(0, 10, 10)\n",
    "\n",
    "plt.hist([df[df.race == 'Caucasian']['decile_score'], \n",
    "          df[df.race == 'African-American']['decile_score']], \n",
    "         bins, label=[\"blue\", \"orange\"])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above observation can be explained by a dependence between the race and true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>two_year_recid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>African-American</th>\n",
       "      <td>1514</td>\n",
       "      <td>1661</td>\n",
       "      <td>0.523150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caucasian</th>\n",
       "      <td>1281</td>\n",
       "      <td>822</td>\n",
       "      <td>0.390870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>320</td>\n",
       "      <td>189</td>\n",
       "      <td>0.371316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native American</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>219</td>\n",
       "      <td>124</td>\n",
       "      <td>0.361516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "two_year_recid       0     1      rate\n",
       "race                                  \n",
       "African-American  1514  1661  0.523150\n",
       "Asian               23     8  0.258065\n",
       "Caucasian         1281   822  0.390870\n",
       "Hispanic           320   189  0.371316\n",
       "Native American      6     5  0.454545\n",
       "Other              219   124  0.361516"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recidivism rates by race\n",
    "recid_race = pd.crosstab(df.race, df.two_year_recid)\n",
    "recid_race['rate'] = recid_race[1] / recid_race.sum(axis=1)\n",
    "recid_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at whether we observe a similar phenomenon on the text scores of COMPAS (low, medium, high risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>score_text</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Medium</th>\n",
       "      <th>High risk rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>African-American</th>\n",
       "      <td>845</td>\n",
       "      <td>1346</td>\n",
       "      <td>984</td>\n",
       "      <td>0.266142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caucasian</th>\n",
       "      <td>223</td>\n",
       "      <td>1407</td>\n",
       "      <td>473</td>\n",
       "      <td>0.106039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>47</td>\n",
       "      <td>368</td>\n",
       "      <td>94</td>\n",
       "      <td>0.092338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Native American</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>22</td>\n",
       "      <td>273</td>\n",
       "      <td>48</td>\n",
       "      <td>0.064140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "score_text        High   Low  Medium  High risk rate\n",
       "race                                                \n",
       "African-American   845  1346     984        0.266142\n",
       "Asian                3    24       4        0.096774\n",
       "Caucasian          223  1407     473        0.106039\n",
       "Hispanic            47   368      94        0.092338\n",
       "Native American      4     3       4        0.363636\n",
       "Other               22   273      48        0.064140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high risk rates by race\n",
    "score_race = pd.crosstab(df.race, df.score_text)\n",
    "score_race['High risk rate'] = score_race['High'] / score_race.sum(axis=1)\n",
    "score_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics for the COMPAS scores\n",
    "\n",
    "We do not have the actual scores that are used to compte text scores Low-Med-High; hence we cannot investigate directly the calibration. However, we can use the decile score as a proxy, and we can investigate PPV. \n",
    "\n",
    "Let us first plot the probability of recidivism by decile score. We observe that it is not very far from a diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:6540\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6534\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6538\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6539\u001b[0m ):\n\u001b[1;32m-> 6540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:12417\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12412\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12415\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12416\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12419\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:12374\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12372\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[0;32m  12376\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:6448\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6447\u001b[0m     )\n\u001b[1;32m-> 6448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string 'miguel hernandezmarsha mileselizabeth thiemekortney colemancraig gilbertmario hernandezrussell sottilemark friedlandporfirio zamotmichael harperrodney danielsvictor cabreramaciashector hollismerlita hansonpedro rodriguezdesmond leemichael kohlerdeanna murphysharon murientesandra quinonesandrew chugia dreisscynthia graycarlos lacayobrian fullerjusto ariasoscar lloranzokwai lammarcial regidorronald castanedarichard robertsdouglas eatondamond craighenry nesbitttamara powerskeron edwardshenson thomaskip stubbstania quinonezedward connellmichael cunninghammichael gellertpatria barnesjohnny toussaintruth etiennekaren storey-broderickalfranzwell myerschristopher wolterkarl weimarmanuel luquesteven luxlunie mathurinkeishon reevesjeffrey andersonann-marie cassagnolstephen kushnertracee chang-scottrafael maganastephen harmonsarada mittapallibarry rabinowitzjohn cooperjacob maynardsandra codorniudaria demarinisfrantz pointdujourmarvin butlerevelyn riveraconstance greenejean lumenedean serfisleslie fanningronelson starkraul moraalejandro remisaaron hullandercarlos rosariorobson de souzathomas zarembaanthony louischristopher kastenjason andrewsrobert zinserrichard brownderrick stephensonbradley kirkerdori kleinkevin connorsjason padillaraymond wolfjorge morenogregory wilsondeborah zacharyfreddy cardonabarbara phetakounekareem williamssastri abhilashbenjamin levinearrantes greenmalcolm austinmilton martineva downskeith antolickgeoffrey salesmanattique mohammadvictor lozadalawrence derubeisdavid hallbenny evansadriana valenciadonnie aguilarluis moravernee mckenziecindy lambkekevin parkerremo bosi-godomarcarmelo aquinokelos francoiscurtis coombsjackson clerisierjonathan nevarezgregory thorntonrigoberto vasquezlimasivor singhalbalidia torresanthony smithlonnie paccionewilliam karlsonzacchius boycebart stormandre levypaul hendersonjoseph costinobrandon allengregory stillgregory osmankent rizonedmund callahanedwin swintonrosalind townsendchristopher kiefermackenson revoluskevin kendallira butlershamroy westalfonso puellodemetria jonesruth fullertonsean claesgensemmanuel philogenejustin mccarthygregg diprimadarrin hillmohammed ahmeddeneen brownsam mitchellarmando friascharles caveyhector contrerasmichelet orismejose villaltanora demmerttheresa brookscatherine manaritekim mcconndarril wilsonleonor ramirezjorge castanedaconsuelo mellalloren andreumark marchantally chattmancarlos gabrielefinest williamsaaron rolleharvell watsonpeter raponehugo garciamarcelo davilaleonardo collazoskeith dillmanfrancisco gonzalezjulio avilesvictoria phillipscatherine blackwoodkurt vanassereynold cadetmasoom aliricardo morenomark hardendawn klueniephillip hopsonelisa garciacrystal lyerlagregory lundyalan suarezmesamoris lucerodakenson placidemichael phelanmaximo castrolonny paulrobert reevestimothy davisroxana ebankspaul sifuentesdonald downingedy chavarriacalderonchristina garrisonchristopher dadapatsy kennedyjeffrey dolgansheila trovatonorberto garciachristopher crespopaulette clarkeulises gonzalezsanchezbobby sturdivantjesus zacariasmark ramseymario browntodd hayesjarrell weaverrolfi hernandezkelby contrerasjenice siscocrystal fallonjames obrienrachelle lindoroylon coppinlloyd kapellbrian spurginrainel garciacotowilliam carlislegerald russomanorichard carinoyoandy vidaljamal brownkelvin nguyenharyidial lallricardo quinonesdarrell sieldino salernomelton mustafasam wumelinda delionsbryan berryjaircinio munozwaldren wrightbrian cunninghamjamie rosenteresa lliterasjames shupeagustin perez-vidaljavier valdesroland muzzimichel dorsainvillerose moscokevin hudsonpatrick keaneparris bradyanthony jacksoncraig colemanjames ravinomelinda huffmanbilly henleyleo beckfordguillermo menaandrew gordonjacques alinstanternestine parrishoneil ebanksthomas whalenalfonso hamiltonkenneth alvarezjoseph mcmahonalex kantzelisleah heingeorge zargosmichael burgessmichael hinosvaldo rodriquezdavid huttonevience aimeedward markovalentin subuchristopher agapayjohn lopezivan paredesadrian phillipsstanley lemorinpamela corriveaujason sucarichieverley davispaula randazzocarlos allenarismendy guareno-coronabonita welchzebedee taylorcharles tientndavid manningjermane fearonbryan scottnorman willisrobert mcphersongary dyeralexander salowregina fergusonjean phanordfernando morenomark vitalejames lowrywalter meixnermanuel menanigel davisareej dorrietyjaqueline robertschad burnsidearthur campbelllucia abreucarmen fontesholger doerrhoward carterfrank cicciobenjamin chasedouglas delarosatanamra brackettdouglas bergmanrita iscarojose somarriba-barrerabrian fieldsalicja maxwellkelly lestradebenedicio salascheryl smithbrian vasquezasael rodriguezlucane jean-baptistejohn mcginnisrobert foxmaribell guzmangary karpgregory oktavecjaime londonoglenn millernelson zunigaeric tesslerroosevelt majorxiao lingnaomi wermanwilliam codyjimmy iakovakisricardo sinclairdomingo alonzoantonio lightbournedward tuckrobert hechtdanue walkertyrone reynarobert jacoberic alstonyuli gurlanikdavid brownralph woodwardaston baileyralph wessellsblair wrightantonio rivaselithanne lucthamasthomas handyjason gardnerjean guerriershemeka suggstanika brownleekhalil elasraouisamuel clarkelawanneka burtonmaurice terryalexey ryabovbrian denbyemmanuel raymondjohane kemprichard lemmonxochitl robertsmichael leighjaime rivasadriana juradogiuseppe daalerrol freckletonbrad clarkjavon harrisjohn goughmotilall noktapaul degiovannimarlo warthenignacio beguiristainronald lakepeter castanonlori foerstercynthia montalvoernesto arduzkevin leeeduard blancomichael levydavid margadonnachristopher obrienjean maximekeith plewsgregory luffhuberman saintilyvon agenorddonald brundidgediego delgadillomarie altenorramon harriskevin oconnellraymond burrlester aguilaranthony deaneugene vaughngreg godettechristina parkerjose santosdemetrice boonemichael cunninghamvidal cervantesherold delinoisjason herringjames conroysammy garciapaulo lapajames trueedson ferrarijesus meleroisaac pardoalexis kelmannclaude grenonangel dejesuscraig lattimorejulio salemjonas garcondale hargrovecarlos ramirezdiazsterlyn ayresvictor levellronald burnsstella ashenpatricio regaldodanielle sitesmoises delgadohassan ahmedjason millsdwayne taylorjoseph leeksadolfo cascostephen kasdorframon velez-cupelesgina leonkeisha granttesa edwardsallatia hogantania quakninenorma villalobosnikson suffrinenrick williamsjulian garsonbaquerochristopher shumanjorge vegafranklin rousenatacha cherenfantgregory tauberstuart rubinlisset llaurocarlos montalvoalexander smithmichael szerkinsgarth richardsryan wisdomdavid pennantmary watsonclearence jenkinsemilio colonmarlene scollonjohn vansteenkistebrandon emmertrandy munozrichard espinozanelson vallerobert echolsjohn nicolasemmanuel pereyrashoaib khangiuseppe montalbanovictor quinonesjohn trentmanedmund witkowskilea ferrerdavid wilsonmarleme louimacourtney hutchinsonguiteau augusterichard turellojerome simminsderrick hepburnhazel baptist-murilloallan harrisbess lambangela margisonandrew pardophillip jaggonanthony ramirezwyche cardalinger kirkeleitsergio rastellibarney arnolderic floydotis shellyvan lewisbrian dalysidney perkinssheri kucherickvictor osejonesler dumerajamaal alleynejose pantaleonandre hamiltonraphael cabricesalrick francisrichard foxroger nettlesjames luxamaroy munroandre viruezdeamon anglinanthony phillipsjonathan tovarrajdaye maharajhcharles delisireyaz blackettmichael higginslee wechslerjohn deprimarichard kirkcarlos perezzambranofrederick bedelljermaine buchananrodney monroejameka fergusonrodger runningvivienne campbellgeorge massieursula fontainegeorge brentrenato schossleradolfo laurentdavid swanedgar cisnerosroosevelt kiservladimir fontaineauta goudreaucarlos calletommie cartermichael denonnoeverson alexisdena gainesrashenna roysterdaniel coxangel hernandezscott jonastalal abouhanaraynard middletonovidio vasquezsuzette tillitsuong huynhalonzo longtherese pattersonkevin burnsjordan robertsdenzle langleyimad farahsteven cooperflora vallierejosue sanchezandria vassellgeorge sislerjorge hourruitinerjeffery mannlindsey jorgensenmary greyvenetta mappdenny riverarobert katharyandrew barnettdouglas masonlouis delvecchioelie duboislynell freemanedward burkskenneth apollolinda altmandavis jirkajoyce jacqueslouisette jeancarlos posadapeter accettastephen cotillorobert leonmaria garciarochilun manassefranklin cedenocarlos ramoswilliam caldercian campbelljondra grierjhims donnerzeke zikriaterry spungerdonnalie higgsdorjan williamsedwin mteicindy guerrierthomas powellchristopher hamiltonsilburn edwardsgiovani castanofelix pachejose jimenezanthony waltersgregory dennisarrow jonesmaurice jonesteresa bennettstacey wiederinsoyeka williamsalexander gorshechnikovjaime bedoyadavid churchpaul hawkinsfernando martinez-salasjesus almeida-garciarodney mcfaddenbond springerbobby grahamjonathan fanfanchristopher maynardgeoffrey wassermanjamye brownsergi shokovlinton coopersem josephgairy palmerfernand elizeemichelle huntershanna kettlethomas rabymarta lopesbrian waltersbarry dambrajeffrey conleyjamie winkleblechhering bolanomarcus gonzalezdouglas duartebruce davisangel lopezturgay fodulshawn demetriusjohn hartsockderric taylorrobert gilbertjahaida zavalamark onuferfernando padronchristopher hallmichael kuruvillajong leepatrick housenjames torgersonnorman reggjacek jodlowskilisa kayealexander jollyisrael lopezjorge almanzacoretta wardpeter mcfieldanne schatzbergtariq raouimaria shermanglenn nievesconcepcion leonpedro lopezgayabrisley pierrewinston hewitteileen milleryonel fatonsusan abrameswayne jensenstuart velkydanielle hahnnaita jamesroger barteauwilny marcteresa hoaglandjoana gomezmartinezbrandon jonesroy raiditimothy petersonkerry richardjason vanderwynkledorothy burgessstephen maxwellglenn bardaeritta covingtondavid gutmanfreddy hallevens periclesjeremy joycerobert crotjulian bastiancarmine dagnelljose ramos-oteroginge brienluis molinabrian dunnbernardo camejobrandon weineryvette paretrobert diersmaggi allairewisler vilcantnoel medinabrunel petit-frererehan kaziramon abreuleon wallacecynthia jacobsstephen castelliveronica talaverathaddeus thomasjocelyn ducardyray lambertleroy rollejoseph suarezjesse teplickimatthew grafthaffi wilsonfelisha jonescephus meltonmary ledbetterdouglas pinedahorace lakemarcelo silvamark murrayleroy baileykatherine pugliesekevin watrousjulietta gustavephat huynhwinston stanleywilliam jamisonjosefa opertscott jimisonnicholas satterfieldkyle johnsonwalter rojasalvin farquharsonyolette cometepeter chovanwally germain-philistinfrantz guerrierdanny diazcourtney brownwilliam walkerrichard tillmanbobby cookpeter liberatorejorge sinisterralefort eugeneprem alvarezjoseph letohictyrone palaciosmarlene russelllinda mashawlloy phillipsmichelle rubin-furtadomaria cecildarren ipmerdis johnsonmartin chaunceykarl smithpathelin felixmelvin brownthomas gunuskeybrent jardineflora emerymarlene decarlosrobert heaglebenjamin fanfanearl williamsherbert morrisdarryl stringeralison coutainalexandra donovanllewellyn jonestiffany morgannicole daleyjames mchelenjays batchanoolinell remekiekim mceachranecarmen manzanaresryan leonardjaime stepptiffaney batsonzida boubacartelford wallacegenevieve savagewillins louisveugopalan devaswamparambilroberto sevillaelvis moralessheridan colliermichael madiaella burburanjerald thorntonjudy fleurimondmichael alenricky burleyshellene thorpereginald foxsemisi afuyonnatan coronellcharlene cousinoreginald hermanvictor falsmiriam torreswalter pharicienjames fieldscharles millersamih debbikmarilyn menendeziffanise fleurinordedgar pugliaemmet sandsjames cantwelldoriano dalessandrorandy pearsonina youngbellpaul fraserhoward hendricksmildred jordanfelix deleonsharon ravitzlynda luckwesley toledonald keltnerrobert livingstonsandra kerseyraymond thompsonpedro bianchiniivan gonzalezcarlos walkershahzad qazikenauld chevelonhoward keroesrene chaparteguytulsiram harnarrinejose figueroalance gonzalezjason bantonpaul mcmullinrichard sofersiarhei marakinmeyer renteriairving emmanueldenise jackson-minottcedric fraserdaniel chiswellchristian johnsonmauricio buitragolarry boydjeanpierre germainranda natoursico charlesemile jonassaintderrick rowedennis tummingsjulia acostamarvin davisgerard fowlerwilliam warringtonadam mccarthybrian calialfonso quesadafred holmesakhter hossaintroy paulkenneth youngalexander castromichael collinsthomas stylesdave jacksoncarol debriaejohn menesestony gotiearlinden andersonderoslyn doreusalberto soloriolaurence stevensjack pierre-louisbyron everettpatricia cerraflaviano leonstephen gornallartis cameronhamlet rodriguez-cabrejastephen hannonchristopher gonzalezsony lundybrian allenchristopher tippettarisno absolujose benitestommy robinsonedgar ceronjack jacksonkimberly ginnieraymond nelsonjames smithmelissa slasonthomas cartermary onealteron sterlingjohn daviswoodson tarincarlos vernemichael ryanradica singhfrancesca larosabernadette fleuryalan burgawanglee georgeerica johnsonnajeh davenportapolinar mezaveron colemangolan feldmangregory williamsrodrigo pinedaboteocarrie salterrayan pinnockgregory youngsamuel wesleyrobert schoenmarie hamiltonmike delgadojames mckenziewilliam bernharddtsebastian cohnleon wilsondanielle cyrregina ewingvanston wardjeffrey sapperjuvince jacqueskevin bunsiemark allenmonica petusevskykyle hansenjamie flynnhilary adlermichael biasucciprecious pricefarrokh mohammadnejadallan castrolawrence baumanglenroy powellmauricio hostioserin baltanadja parishshella rangoowaladonovan goodecelia wagnergeorge turnerrichard danielseric saddlermuzaffer kilicchristopher sheehankenold jeanabraham ballestaseddie deankevin dumeyemonte bankslulio calderondarriss cooperkaren baaderluis gaitandavid lawrenceconstance chapindonovan greenstephen sissoneveline rosenbergsteven henrysabrina khanuberne gonzalezreynaldo meneseswestgard butingbrian bradleyclive brownlalo munozyolanda hoffcedric hynesfernando velazquezhernandezjanet mccarthyjamsly georgeshuy trinhnick maniscalsodelroy henryanne murrayraoul emilelouveni bellscott kaplanmichael lorenzgregory lugodonovan amancody carlsonjuan marineroshannon gopherignacio chorenoeileen dunnkiet hoailton camposlisa orangejosue espinosamatthew motonpaul dillonfay mizrachirobin foychristopher freemanjonathan clearejoseph fallongerman garciadicioccoirangel arochoherbert conleylawrence wanschekcarlos eadysamir soussialens josephtrevor grosholzsilvio lopezfrederick vetenskycatherine scherdeborah spothmario luisjohn kempbridgette obermanwilner josephbroderick lewislionel saconjames bruschettirichard fleenorjerome hillallande pierreangel williscorey parchmentangel francoshane forshawfrederick gallawayjuan guevararobert gradymark ribeirojesus roaramon matutehussain hussainjean georgesemanoil faneavictor jironwilmer artetadaniel gonzalezemma daviskimberly warerichard spitlerdagobret schmalhausjonathan olazabalmartin espinozagerard spelmanfredrick grantzandra haywooddouglas schnoorpaul bergeronkellie werbawilly jeanmiguel vegariveraeusebio diaz acostaleland mclaughlinkevin gilmoreulrike ballesterosroger goindootheova milfortglasford prehayfanny penanorrissie howardmimmose nicolasandres powerjustin armstrongwilfred bryanjailton sousabernard millerstorm palmercarlo marraaurelia coffeygrace harrisherman holmesbryan mcdouglemikrko casalinorichar aymearealious griercindy suttonpaola collado-izquierdokim anthonychristian giraldofoufoune juniorcarol hopkinsonmelina delgadodominick dinittostephen hilllarry navillewendy martinezmichael fazakerleyshlomi asayagefrain garcialarry hamptonvenson josephasher robertianthony piroloirina roginagloria mosesroland voltaireimad cherifdanny abadiavitay josephnicholas wrightyvette calderonviccas harrisjuan oliverwilliam larsonedward mcclainyvonne whorriemargarita simonsidney moodyrobert watsonvaughn kellingbeckandre uterangela wallerbryan ashleyqushondra fieldsonique williamsjean fils-aimewilfredo torresadriano suarezkevin abelljason bouchermarlon dunlopbrian butchernancy howardbrittany holtzulimay lizcanokevin maitlandsheron williamskim aragonadaryl junckjustin warnermedius clermontvilcorey ackermanwilliam agurontfrancisco huertaruth battistemaria santiagoyoleida santiagochristopher petinaudjohn pereirateoman algurjames felderthery cineusanthony angottirobert maderahowell abrahamacie canteenrosny abrahamavian grantdaniel staimescott kaplangeranie barthelemyandre bandieclara igelesiascharles fichtnerthelma lopezmorris atkinsalvyn domanwilliam ogburnpaul daleynorval kellynoel sequeiraivan peraltafrantz benechemaxine peartsyrefia kinchenjohn mompremierhamilton claringtonali jumagiovanna floresbarton schroederivette lopezmichael ventorosemary marchalchristopher jordanolga baumphilip jamisonjulio matamorosnikolay petrovgervaise hyltonjason bartleymario delrioanthony wellsadam rodgerswilliam jarjourana mejarodriguezraul castroluis melendezkerri reid-cookscraig evanssylvia sarnerpaul sladerabbir hossainnoel lopezbrian guillendaniel wickyves souffrantmaura mitchelljohn taddeonelson bauzajennifer crowejudith guadaginoflavio silvacourtney knochemichael blackbruce gersonmonica churchilldavid kelleymassiel espinosabruce burdinmiguel penarenee lamarchedaniella octelusricky arnesontwana williamsmartin martinezallen willeymarquis taylorronald salesjames sauergarland humpherieschristopher pulsiferluis quinteroberry sandersroger nicholsjaynell bristolgeorge mihelichrobert yagglevincent lewisjesus palomoluis garciajoshua maxwelldouglas bellgina hawkinsmuhammad altafjeanne allensixto durandismael ramoskatherine cambarerigeorge dunganlinda dawsonshameel koyaarleen martinangelita diazwinston gregory' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# probability of recidivism by decile\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecile_score\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo_year_recid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# probability of recidivism by decile\n",
    "df.groupby(df.decile_score).mean()['two_year_recid'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO</span>: Plot a similar graph with separated bars for Blacks and Whites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of recidivism by decile and race\n",
    "# TODO: Insert your code below this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further analyze the COMPAS score as a classifier, we transform it into a binary outcome by splitting \"low\" (class 0) from \"medium or high\" risk (class 1). We can then compute standard quantities such as the confusion matrix or PPV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPAS recidivism confusion matrix\n",
    "df['guessed_recid'] = df.score_text != 'Low'\n",
    "df['actual_recid'] = df.two_year_recid == 1\n",
    "cm = pd.crosstab(df.actual_recid, df.guessed_recid)\n",
    "cm # for \"confusion matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally compute the PPV, TPR and FPR of the COMPAS classifier. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Complete the print_ppv_fpv function. Observe the differences in the metrics between Blacks and Whites and comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm is a confusion matrix. The rows are guessed, the columns are actual \n",
    "def print_ppv_fpv(cm):\n",
    "    # the indices here are [col][row] or [actual][guessed]\n",
    "    TN = cm[False][False]   \n",
    "    TP = cm[True][True]\n",
    "    FN = cm[True][False]\n",
    "    FP = cm[False][True]\n",
    "# TODO: Uncomment the lines below and replace the ... by the appropriate expressions of TN, TP, FN, FP  \n",
    "#     print('Accuracy: ', ...)\n",
    "#     print('PPV: ', ...)\n",
    "#     print('FPR: ', ...)\n",
    "#     print('FNR: ', ...)\n",
    "#     print()\n",
    "#\n",
    "\n",
    "\n",
    "def print_metrics(guessed, actual):\n",
    "    cm = pd.crosstab(guessed, actual, rownames=['guessed'], colnames=['actual'])\n",
    "    print(cm)\n",
    "    print()\n",
    "    print_ppv_fpv(cm)   \n",
    "    \n",
    "print('White')\n",
    "subset = df[df.race == 'Caucasian']\n",
    "print_metrics(subset.guessed_recid, subset.actual_recid)\n",
    "\n",
    "print('Black')\n",
    "subset = df[df.race == 'African-American']\n",
    "print_metrics(subset.guessed_recid, subset.actual_recid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the False Positive Rate is substantially higher for black defendants, but the PPV is similar between blacks and whites. That is, the COMPAS score satisfies sufficiency, but not separation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier from the ground truth label\n",
    "\n",
    "We now train a classifier (a simple logistic regression) on the label two_year_recid. We work on a subset of features: [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"]. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Complete the model definition and fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict\n",
    "\n",
    "FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"] #features to be used for classification\n",
    "CONT_VARIABLES = [\"priors_count\"] # continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot\n",
    "CLASS_FEATURE = \"two_year_recid\" # the decision variable\n",
    "SENSITIVE_ATTRS = [\"race\"]\n",
    "\n",
    "\n",
    "y = data[CLASS_FEATURE]\n",
    "X = np.array([]).reshape(len(y), 0) # empty array with num rows same as num examples, will hstack the features to it\n",
    "x_control = defaultdict(list)\n",
    "\n",
    "for attr in FEATURES_CLASSIFICATION:\n",
    "    vals = data[attr]\n",
    "    if attr in CONT_VARIABLES:\n",
    "        vals = [float(v) for v in vals]\n",
    "        vals = preprocessing.scale(vals) # 0 mean and 1 variance  \n",
    "        vals = np.reshape(vals, (len(y), -1)) # convert from 1-d arr to a 2-d arr with one col\n",
    "\n",
    "    else: # this encodes categorical variables in a numerical way -- there are other ways to do it\n",
    "        enc = preprocessing.LabelBinarizer()\n",
    "        enc.fit(vals)\n",
    "        vals = enc.transform(vals)\n",
    "\n",
    "    # add to learnable features\n",
    "    X = np.hstack((X, vals))\n",
    "\n",
    "    \n",
    "# the following is a very dirty way to keep track of the race after the train_test_split    \n",
    "ind = data[\"race\"]==\"African-American\"\n",
    "X_b = X[ind] \n",
    "y_b = y[ind]\n",
    "ind = data[\"race\"]==\"Caucasian\"\n",
    "X_w = X[ind]        \n",
    "y_w = y[ind]\n",
    "ind = [data[\"race\"][i]!=\"Caucasian\" and data[\"race\"][i]!=\"African-American\" for i in range(len(y))]\n",
    "X_n = X[ind]        \n",
    "y_n = y[ind]\n",
    "    \n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=0.3, random_state=1234)\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_w, y_w, test_size=0.3, random_state=5678)\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_n, y_n, test_size=0.3, random_state=9012)\n",
    "\n",
    "X_train = np.vstack((X_train_b, X_train_w, X_train_n))\n",
    "y_train = np.hstack((y_train_b, y_train_w, y_train_n))\n",
    "X_test = np.vstack((X_test_b, X_test_w, X_test_n))\n",
    "y_test = np.hstack((y_test_b, y_test_w, y_test_n))\n",
    "\n",
    "\n",
    "# TODO: Uncomment and complete the code below\n",
    "# model = ...\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the model accuracy. Compare to the COMPAS accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the ROC curve for the model on the global population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scores = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, scores[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.title('ROC overall population')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO</span>: Plot the ROC curve for Blacks and Whites in two separate curves (in the same plot). What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert your code below this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally check the fairness of this simple logistic regression, when choosing an arbitrary threshold common to the two groups. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Compute the predictions for a common threshold (threshold_common), then compute the PPV, TPR, FPR (you can use the print_metrics function from above). Comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_common = 0.5\n",
    "# TODO: Insert your code below this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also investigate the calibration more finely using the calibration module from sklearn. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Complete the code below to plot the calibration curve for the whole population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "# TODO: Uncomment and complete the code below\n",
    "# scores = ...\n",
    "# prob_true, prob_pred = ...\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only this line is calibration curves\n",
    "plt.plot(prob_pred,prob_true, marker='o', linewidth=1, label='all')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot for the logistic regression (overall)')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO</span>: Complete the code below to plot the calibration curve for the blacks and white separately. Conclude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment and complete the code below\n",
    "# ...\n",
    "# prob_true_b, prob_pred_b = ...\n",
    "# ...\n",
    "# prob_true_w, prob_pred_w = ...\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only this line is calibration curves\n",
    "plt.plot(prob_pred_b,prob_true_b, marker='o', linewidth=1, label='Blacks')\n",
    "plt.plot(prob_pred_w,prob_true_w, marker='o', linewidth=1, label='Whites')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot for the logistic regression (overall)')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
