{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first analysis of the COMPAS dataset\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "We will examine the ProPublica COMPAS dataset, which contains the records of all criminal defendants who were subject to COMPAS screening in Broward County, Florida, during 2013 and 2014. For each defendant, various information fields (‘features’) were gathered by ProPublica. Broadly, these fields are related to the defendant’s demographic information (e.g., gender and race), criminal history (e.g., the number of prior offenses) and administrative information about the case (e.g., the case number, arrest date). Finally, the dataset contains the risk of recidivism predicted by the COMPAS tool, and also information about whether the defendant did actually recidivate or not (ground truth label for us).\n",
    "\n",
    "The COMPAS score uses answers to 137 questions to assign a risk score to defendants -- essentially an estimate of the likelihood of re-arrest. The actual output is two-fold: a risk rating of 1-10 and a \"low\", \"medium\", or \"high\" risk label.\n",
    "\n",
    "Link to dataset: https://github.com/propublica/compas-analysis\n",
    "\n",
    "The file we will analyze is: compas-scores-two-years.csv\n",
    "\n",
    "Link to the ProPublica article:\n",
    "\n",
    "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "\n",
    "Some of the code below is adapted from the Propublica github repository above, and from\n",
    "\n",
    "https://investigate.ai/propublica-criminal-sentencing/week-5-1-machine-bias-class/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "We first need to load the data from the ProPublica repo:\n",
    "https://github.com/propublica/compas-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilyin\\AppData\\Local\\Temp\\ipykernel_4864\\1500087627.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for file '%s' in the current directory... compas-scores-two-years.csv\n",
      "'%s' not found! Downloading from GitHub... compas-scores-two-years.csv\n",
      "'%s' download and saved locally.. compas-scores-two-years.csv\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import urllib.request\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import preprocessing\n",
    "from random import seed, shuffle\n",
    "\n",
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def check_data_file(fname):\n",
    "    files = os.listdir(\".\") # get the current directory listing\n",
    "    print(\"Looking for file '%s' in the current directory...\",fname)\n",
    "\n",
    "    if fname not in files:\n",
    "        print(\"'%s' not found! Downloading from GitHub...\",fname)\n",
    "        addr = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "        response = urllib.request.urlopen(addr)\n",
    "        data = response.read()\n",
    "        fileOut = open(fname, \"wb\")\n",
    "        fileOut.write(data)\n",
    "        fileOut.close()\n",
    "        print(\"'%s' download and saved locally..\",fname)\n",
    "    else:\n",
    "        print(\"File found in current directory..\")\n",
    "    \n",
    "COMPAS_INPUT_FILE = \"compas-scores-two-years.csv\"\n",
    "check_data_file(COMPAS_INPUT_FILE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning data\n",
    "\n",
    "The following code load the data using pandas and cleans it according to ProPublica's cleaning: \n",
    "\n",
    "\"\n",
    "If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense.\n",
    "\n",
    "We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "\n",
    "In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed\n",
    "\n",
    "We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\" \n",
    "\"\n",
    "\n",
    "Finally, it converts the data to a dictionary with np arrays, which will be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file\n",
    "df = pd.read_csv(COMPAS_INPUT_FILE)\n",
    "# print(df.shape)\n",
    "\n",
    "df = df.dropna(subset=[\"days_b_screening_arrest\"]) # dropping missing vals\n",
    "\n",
    "df = df[\n",
    "    (df.days_b_screening_arrest <= 30) &  \n",
    "    (df.days_b_screening_arrest >= -30) &  \n",
    "    (df.is_recid != -1) &\n",
    "    (df.c_charge_degree != 'O') &\n",
    "    (df.score_text != 'N/A')\n",
    "]\n",
    "\n",
    "df.reset_index(inplace=True, drop=True) # renumber the rows from 0 again\n",
    "# df.shape\n",
    "\n",
    "# Conversion to dictionary with np arrays\n",
    "data = df.to_dict('list')\n",
    "for k in data.keys():\n",
    "    data[k] = np.array(data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>r_days_from_arrest</th>\n",
       "      <th>violent_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "      <td>6172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5509.259883</td>\n",
       "      <td>34.534511</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>4.418503</td>\n",
       "      <td>0.091218</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>-1.740279</td>\n",
       "      <td>24.903273</td>\n",
       "      <td>0.484446</td>\n",
       "      <td>20.100651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>4.418503</td>\n",
       "      <td>3.641769</td>\n",
       "      <td>3.246436</td>\n",
       "      <td>13.316753</td>\n",
       "      <td>555.049417</td>\n",
       "      <td>0.389825</td>\n",
       "      <td>0.455120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3171.878516</td>\n",
       "      <td>11.730938</td>\n",
       "      <td>0.463599</td>\n",
       "      <td>2.839463</td>\n",
       "      <td>0.497872</td>\n",
       "      <td>0.470731</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>5.084709</td>\n",
       "      <td>276.812982</td>\n",
       "      <td>0.499799</td>\n",
       "      <td>76.543499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315539</td>\n",
       "      <td>2.839463</td>\n",
       "      <td>2.488768</td>\n",
       "      <td>4.743770</td>\n",
       "      <td>50.138185</td>\n",
       "      <td>400.258400</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.498022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2753.750000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5521.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>539.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8225.250000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>914.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11001.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9485.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>937.000000</td>\n",
       "      <td>1186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          age  juv_fel_count  decile_score  juv_misd_count  \\\n",
       "count   6172.000000  6172.000000    6172.000000   6172.000000     6172.000000   \n",
       "mean    5509.259883    34.534511       0.059300      4.418503        0.091218   \n",
       "std     3171.878516    11.730938       0.463599      2.839463        0.497872   \n",
       "min        1.000000    18.000000       0.000000      1.000000        0.000000   \n",
       "25%     2753.750000    25.000000       0.000000      2.000000        0.000000   \n",
       "50%     5521.000000    31.000000       0.000000      4.000000        0.000000   \n",
       "75%     8225.250000    42.000000       0.000000      7.000000        0.000000   \n",
       "max    11001.000000    96.000000      20.000000     10.000000       13.000000   \n",
       "\n",
       "       juv_other_count  priors_count  days_b_screening_arrest  \\\n",
       "count      6172.000000   6172.000000              6172.000000   \n",
       "mean          0.110661      3.246436                -1.740279   \n",
       "std           0.470731      4.743770                 5.084709   \n",
       "min           0.000000      0.000000               -30.000000   \n",
       "25%           0.000000      0.000000                -1.000000   \n",
       "50%           0.000000      1.000000                -1.000000   \n",
       "75%           0.000000      4.000000                -1.000000   \n",
       "max           9.000000     38.000000                30.000000   \n",
       "\n",
       "       c_days_from_compas     is_recid  r_days_from_arrest  violent_recid  \\\n",
       "count         6172.000000  6172.000000         1997.000000            0.0   \n",
       "mean            24.903273     0.484446           20.100651            NaN   \n",
       "std            276.812982     0.499799           76.543499            NaN   \n",
       "min              0.000000     0.000000           -1.000000            NaN   \n",
       "25%              1.000000     0.000000            0.000000            NaN   \n",
       "50%              1.000000     0.000000            0.000000            NaN   \n",
       "75%              1.000000     1.000000            1.000000            NaN   \n",
       "max           9485.000000     1.000000          993.000000            NaN   \n",
       "\n",
       "       is_violent_recid  decile_score.1  v_decile_score  priors_count.1  \\\n",
       "count       6172.000000     6172.000000     6172.000000     6172.000000   \n",
       "mean           0.112119        4.418503        3.641769        3.246436   \n",
       "std            0.315539        2.839463        2.488768        4.743770   \n",
       "min            0.000000        1.000000        1.000000        0.000000   \n",
       "25%            0.000000        2.000000        1.000000        0.000000   \n",
       "50%            0.000000        4.000000        3.000000        1.000000   \n",
       "75%            0.000000        7.000000        5.000000        4.000000   \n",
       "max            1.000000       10.000000       10.000000       38.000000   \n",
       "\n",
       "             start          end        event  two_year_recid  \n",
       "count  6172.000000  6172.000000  6172.000000     6172.000000  \n",
       "mean     13.316753   555.049417     0.389825        0.455120  \n",
       "std      50.138185   400.258400     0.487750        0.498022  \n",
       "min       0.000000     0.000000     0.000000        0.000000  \n",
       "25%       0.000000   148.000000     0.000000        0.000000  \n",
       "50%       0.000000   539.500000     0.000000        0.000000  \n",
       "75%       3.000000   914.000000     1.000000        1.000000  \n",
       "max     937.000000  1186.000000     1.000000        1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # check some examples of data\n",
    "df.columns # prints the features\n",
    "df.isnull().sum() #check for missing values\n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset\n",
    "\n",
    "The following pandas commands are very convenient to explore the data. Uncomment them to explore the data. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Add a command to print the number of defendents per race. \n",
    "\n",
    "In the following, we will look mostly at African-Americans and Caucasians(termed blacks and whites for short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "African-American    3175\n",
       "Caucasian           2103\n",
       "Hispanic             509\n",
       "Other                343\n",
       "Asian                 31\n",
       "Native American       11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # check some examples of data\n",
    "df.columns # prints the features\n",
    "df.isnull().sum() #check for missing values\n",
    "df.describe() # generates descriptive statistics (e.g., to check for outliers)\n",
    "df.race.unique() # different races we have in the dataset\n",
    "df.age_cat.value_counts() #number of people by age category\n",
    "df.score_text.value_counts() #number of people by COMPAS risk category\n",
    "\n",
    "# TODO: Insert your code below this\n",
    "df.race.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis of the bias in COMPAS scores\n",
    "\n",
    "We now look at the COMPAS scores (deciles first, then text scores) as a function of the sensitive attribute (race or gender) to observe potential differences. \n",
    "\n",
    "We start by observing the scores for different groupes. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Plot the histograms of decile scores for Black and White defendant and observe the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': \"White Defendant's Decile Scsores \"}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of decile scores for Blacks (blue) and Whites (orange)\n",
    "# TODO: Insert your code below this\n",
    "\n",
    "df[df.race == 'Caucasian']['decile_score'].plot(kind='hist', title='White Defendant\\'s Decile Scores ')\n",
    "df[df.race == 'African-American']['decile_score'].plot(kind='hist', title='White Defendant\\'s Decile Scores ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above observation can be explained by a dependence between the race and true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recidivism rates by race\n",
    "recid_race = pd.crosstab(df.race, df.two_year_recid)\n",
    "recid_race['rate'] = recid_race[1] / recid_race.sum(axis=1)\n",
    "recid_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at whether we observe a similar phenomenon on the text scores of COMPAS (low, medium, high risk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high risk rates by race\n",
    "score_race = pd.crosstab(df.race, df.score_text)\n",
    "score_race['High risk rate'] = score_race['High'] / score_race.sum(axis=1)\n",
    "score_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness metrics for the COMPAS scores\n",
    "\n",
    "We do not have the actual scores that are used to compte text scores Low-Med-High; hence we cannot investigate directly the calibration. However, we can use the decile score as a proxy, and we can investigate PPV. \n",
    "\n",
    "Let us first plot the probability of recidivism by decile score. We observe that it is not very far from a diagonale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of recidivism by decile\n",
    "df.groupby(df.decile_score).mean()['two_year_recid'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO</span>: Plot a similar graph with separated bars for Blacks and Whites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of recidivism by decile and race\n",
    "# TODO: Insert your code below this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further analyze the COMPAS score as a classifier, we transform it into a binary outcome by splitting \"low\" (class 0) from \"medium or high\" risk (class 1). We can then compute standard quantities such as the confusion matrix or PPV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPAS recidivism confusion matrix\n",
    "df['guessed_recid'] = df.score_text != 'Low'\n",
    "df['actual_recid'] = df.two_year_recid == 1\n",
    "cm = pd.crosstab(df.actual_recid, df.guessed_recid)\n",
    "cm # for \"confusion matrix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally compute the PPV, TPR and FPR of the COMPAS classifier. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Complete the print_ppv_fpv function. Observe the differences in the metrics between Blacks and Whites and comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm is a confusion matrix. The rows are guessed, the columns are actual \n",
    "def print_ppv_fpv(cm):\n",
    "    # the indices here are [col][row] or [actual][guessed]\n",
    "    TN = cm[False][False]   \n",
    "    TP = cm[True][True]\n",
    "    FN = cm[True][False]\n",
    "    FP = cm[False][True]\n",
    "# TODO: Uncomment the lines below and replace the ... by the appropriate expressions of TN, TP, FN, FP  \n",
    "#     print('Accuracy: ', ...)\n",
    "#     print('PPV: ', ...)\n",
    "#     print('FPR: ', ...)\n",
    "#     print('FNR: ', ...)\n",
    "#     print()\n",
    "#\n",
    "\n",
    "\n",
    "def print_metrics(guessed, actual):\n",
    "    cm = pd.crosstab(guessed, actual, rownames=['guessed'], colnames=['actual'])\n",
    "    print(cm)\n",
    "    print()\n",
    "    print_ppv_fpv(cm)   \n",
    "    \n",
    "print('White')\n",
    "subset = df[df.race == 'Caucasian']\n",
    "print_metrics(subset.guessed_recid, subset.actual_recid)\n",
    "\n",
    "print('Black')\n",
    "subset = df[df.race == 'African-American']\n",
    "print_metrics(subset.guessed_recid, subset.actual_recid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: the False Positive Rate is substantially higher for black defendants, but the PPV is similar between blacks and whites. That is, the COMPAS score satisfies sufficiency, but not separation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier from the ground truth label\n",
    "\n",
    "We now train a classifier (a simple logistic regression) on the label two_year_recid. We work on a subset of features: [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"]. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Complete the model definition and fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict\n",
    "\n",
    "FEATURES_CLASSIFICATION = [\"age_cat\", \"race\", \"sex\", \"priors_count\", \"c_charge_degree\"] #features to be used for classification\n",
    "CONT_VARIABLES = [\"priors_count\"] # continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot\n",
    "CLASS_FEATURE = \"two_year_recid\" # the decision variable\n",
    "SENSITIVE_ATTRS = [\"race\"]\n",
    "\n",
    "\n",
    "y = data[CLASS_FEATURE]\n",
    "X = np.array([]).reshape(len(y), 0) # empty array with num rows same as num examples, will hstack the features to it\n",
    "x_control = defaultdict(list)\n",
    "\n",
    "for attr in FEATURES_CLASSIFICATION:\n",
    "    vals = data[attr]\n",
    "    if attr in CONT_VARIABLES:\n",
    "        vals = [float(v) for v in vals]\n",
    "        vals = preprocessing.scale(vals) # 0 mean and 1 variance  \n",
    "        vals = np.reshape(vals, (len(y), -1)) # convert from 1-d arr to a 2-d arr with one col\n",
    "\n",
    "    else: # this encodes categorical variables in a numerical way -- there are other ways to do it\n",
    "        enc = preprocessing.LabelBinarizer()\n",
    "        enc.fit(vals)\n",
    "        vals = enc.transform(vals)\n",
    "\n",
    "    # add to learnable features\n",
    "    X = np.hstack((X, vals))\n",
    "\n",
    "    \n",
    "# the following is a very dirty way to keep track of the race after the train_test_split    \n",
    "ind = data[\"race\"]==\"African-American\"\n",
    "X_b = X[ind] \n",
    "y_b = y[ind]\n",
    "ind = data[\"race\"]==\"Caucasian\"\n",
    "X_w = X[ind]        \n",
    "y_w = y[ind]\n",
    "ind = [data[\"race\"][i]!=\"Caucasian\" and data[\"race\"][i]!=\"African-American\" for i in range(len(y))]\n",
    "X_n = X[ind]        \n",
    "y_n = y[ind]\n",
    "    \n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, y_b, test_size=0.3, random_state=1234)\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_w, y_w, test_size=0.3, random_state=5678)\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(X_n, y_n, test_size=0.3, random_state=9012)\n",
    "\n",
    "X_train = np.vstack((X_train_b, X_train_w, X_train_n))\n",
    "y_train = np.hstack((y_train_b, y_train_w, y_train_n))\n",
    "X_test = np.vstack((X_test_b, X_test_w, X_test_n))\n",
    "y_test = np.hstack((y_test_b, y_test_w, y_test_n))\n",
    "\n",
    "\n",
    "# TODO: Uncomment and complete the code below\n",
    "# model = ...\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the model accuracy. Compare to the COMPAS accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the ROC curve for the model on the global population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scores = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, scores[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.title('ROC overall population')\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO</span>: Plot the ROC curve for Blacks and Whites in two separate curves (in the same plot). What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Insert your code below this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally check the fairness of this simple logistic regression, when choosing an arbitrary threshold common to the two groups. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Compute the predictions for a common threshold (threshold_common), then compute the PPV, TPR, FPR (you can use the print_metrics function from above). Comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_common = 0.5\n",
    "# TODO: Insert your code below this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also investigate the calibration more finely using the calibration module from sklearn. \n",
    "\n",
    "<span style=\"color:red\">TODO</span>: Complete the code below to plot the calibration curve for the whole population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "# TODO: Uncomment and complete the code below\n",
    "# scores = ...\n",
    "# prob_true, prob_pred = ...\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only this line is calibration curves\n",
    "plt.plot(prob_pred,prob_true, marker='o', linewidth=1, label='all')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot for the logistic regression (overall)')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">TODO</span>: Complete the code below to plot the calibration curve for the blacks and white separately. Conclude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment and complete the code below\n",
    "# ...\n",
    "# prob_true_b, prob_pred_b = ...\n",
    "# ...\n",
    "# prob_true_w, prob_pred_w = ...\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only this line is calibration curves\n",
    "plt.plot(prob_pred_b,prob_true_b, marker='o', linewidth=1, label='Blacks')\n",
    "plt.plot(prob_pred_w,prob_true_w, marker='o', linewidth=1, label='Whites')\n",
    "\n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot for the logistic regression (overall)')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
